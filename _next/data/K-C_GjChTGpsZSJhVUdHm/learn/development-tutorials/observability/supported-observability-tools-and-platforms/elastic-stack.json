{"pageProps":{"frontmatter":{"title":"Observe logs using Elastic Stack","description":"See how Ballerina supports observability by exposing its logs to Elastic Stack.","keywords":"ballerina, observability, metrics, tracing, elastic stack","permalink":"/learn/supported-observability-tools-and-platforms/elastic-stack/","active":"elastic-stack","intro":"In Ballerina, distributed logging and analysis are supported by the [Elastic Stack](https://www.elastic.co/elastic-stack). Ballerina has a log module for logging into the console. To monitor the logs, the Ballerina standard output needs to be redirected to a file."},"content":"\nThe Elastic Stack comprises the following components.\n\n1. **Beats** - Multiple agents that ship data to Logstash or Elasticsearch. In our context, Filebeat will ship the Ballerina logs to Logstash. Filebeat should be a container running on the same host as the Ballerina service. This is so that the log file (ballerina.log) can be mounted to the Filebeat container.\n2. **Logstash** - Used to process and structure the log files received from Filebeat and send them to Elasticsearch.\n3. **Elasticsearch** - Storage and indexing of the logs sent by Logstash.\n4. **Kibana** - Visualizes the data stored in Elasticsearch.\n\nThe sample [shop service](/learn/overview-of-ballerina-observability/#example-observe-a-ballerina-service) will be used in this guide. Follow the steps given below to observe Ballerina logs in Elastic Stack.\n\n## Step 1 - Set up Elastic Stack\n\nElasticsearch and Kibana are provided as <a href=\"https://www.elastic.co/cloud\" target=\"_blank\">Cloud services</a>. Alternatively, Docker containers can be used to set up Elasticsearch and Kibana as well.\n\n1. Download the Docker images using the following commands.\n\n    ```\n    # Elasticsearch Image\n    $ docker pull docker.elastic.co/elasticsearch/elasticsearch:8.15.2\n    # Kibana Image\n    $ docker pull docker.elastic.co/kibana/kibana:8.15.2\n    # Filebeat Image\n    $ docker pull docker.elastic.co/beats/filebeat:8.15.2\n    # Logstash Image\n    $ docker pull docker.elastic.co/logstash/logstash:8.15.2\n    ```\n\n2. Start Elasticsearch and Kibana containers by executing the following commands.\n\n    ```\n    $ docker run -p 9200:9200 -p 9300:9300 -it -h elasticsearch --name elasticsearch docker.elastic.co/elasticsearch/elasticsearch:8.15.2\n    $ docker run -p 5601:5601 -h kibana --name kibana --link elasticsearch:elasticsearch docker.elastic.co/kibana/kibana:8.15.2\n    ```\n    \n    If you are using Linux, you may have to increase the `vm.max_map_count` for the Elasticsearch container to start. \n    Execute the following command to do that.\n    \n    ```\n    $ sudo sysctl -w vm.max_map_count=262144\n    ```\n\n3. Create a `logstash.conf` file in the `/tmp/pipeline/` directory and include the following content in the file.\n\n    ```\n    input {\n      beats {\n        port => 5044\n        }\n    }\n    filter {\n      grok  {\n        match => { \"message\" => \"%{TIMESTAMP_ISO8601:date}%{SPACE}%{WORD:logLevel}%{SPACE}\\[%{GREEDYDATA:module}\\]%{SPACE}\\-%{SPACE}%{GREEDYDATA:logMessage}\"}\n      }\n    }\n    output {\n        elasticsearch {\n            hosts => \"elasticsearch:9200\"\n            index => \"ballerina\"\n          document_type => \"ballerina_logs\"\n        }\n    }\n    ```\n    \n    Here, the 3 stages are specified in the pipeline. Input is specified as beats and listens to port 5044. \n    A Grok filter is used to structure the Ballerina logs and the output is specified to push to Elasticsearch on\n    `elasticsearch:9200`.\n\n4. Start the Logstash container by executing the following command.\n\n    ```\n    $ docker run -h logstash --name logstash --link elasticsearch:elasticsearch -it --rm -v /tmp/pipeline:/usr/share/logstash/pipeline/ -p 5044:5044 docker.elastic.co/logstash/logstash:8.15.2\n    ```\n\n5. Configure Filebeat to ship the Ballerina logs. Create a `filebeat.yml` file in the `/tmp/` directory and include the following content in the file.\n\n    ```\n    filebeat.prospectors:\n    - type: log\n      paths:\n        - /usr/share/filebeat/ballerina.log\n    output.logstash:\n      hosts: [\"logstash:5044\"]\n    ```\n    \n6. Start the Filebeat container with the following command.\n\n    ```\n    $ docker run -v /tmp/filebeat.yml:/usr/share/filebeat/filebeat.yml -v /<path-to-ballerina.log>/ballerina.log:/usr/share/filebeat/ballerina.log --link logstash:logstash docker.elastic.co/beats/filebeat:8.15.2\n    ```\n    \n    The `-v` flag is used for bind mounting, where the container will read the file from the host machine. Provide the path to the `ballerina.log` file to be bind-mounted to the filebeat container.\n\n## Step 2 - Run Ballerina Service\n\nThis can be done by running the Ballerina service as below.\n\n```\n$ nohup bal run main.bal > ballerina.log &\n```\n\nYou can view the logs with the command below.\n\n```\n$ tail -f ~/wso2-ballerina/workspace/ballerina.log\n```\n\n## Step 3 - Send requests\n\nSend requests to <http://localhost:8090/shop/products>.\n\nExample cURL commands:\n\n```\n$ curl -X GET http://localhost:8090/shop/products\n```\n```\n$ curl -X POST http://localhost:8090/shop/product \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"id\": 4, \n    \"name\": \"Laptop Charger\", \n    \"price\": 50.00\n}'\n```\n```\n$ curl -X POST http://localhost:8090/shop/order \\\n-H \"Content-Type: application/json\" \\\n-d '{\n    \"productId\": 1, \n    \"quantity\": 1\n}'\n```\n```\n$ curl -X GET http://localhost:8090/shop/order/0\n```\n\n## Step 4 - View logs on Kibana\n\nAccess Kibana to visualize the logs at <http://localhost:5601>. Add an index named `ballerina` and click on `Discover` to visualize the logs.\n","id":"elastic-stack","sub":"observability","third":"supported-observability-tools-and-platforms","slug":"observability/supported-observability-tools-and-platforms/elastic-stack","codes":"[]"},"__N_SSG":true}