{"pageProps":{"frontmatter":{"layout":"ballerina-observing-programs-left-nav-pages-swanlake","title":"Observe Ballerina Programs","description":"See how Ballerina supports observability by exposing itself via metrics, tracing, and logs to external systems.","keywords":"ballerina, observability, metrics, tracing, logs, prometheus, grafana, jaeger, elastic","permalink":"/learn/observe-ballerina-programs/","active":"observe-ballerina-programs","intro":"Observability is a measure of how well the internal states of a system can be inferred from the knowledge of its external outputs.","redirect_from":["/learn/how-to-observe-ballerina-code","/learn/how-to-observe-ballerina-code/","/learn/how-to-observe-ballerina-services/","/learn/how-to-observe-ballerina-services","/learn/observing-ballerina-code","/swan-lake/learn/observing-ballerina-code/","/swan-lake/learn/observing-ballerina-code","/learn/observing-ballerina-code/","/learn/observing-ballerina-code","/learn/user-guide/observing-ballerina-code","/learn/user-guide/observing-ballerina-code/","/learn/user-guide/observability/","/learn/user-guide/observability","/learn/user-guide/observability/observing-ballerina-code/","/learn/user-guide/observability/observing-ballerina-code","/learn/observing-ballerina-programs/observing-your-application-with-prometheus-grafana-and-jaeger/","/learn/observing-ballerina-programs/observing-your-application-with-prometheus-grafana-and-jaeger","/learn/observing-ballerina-programs/observing-your-application-with-prometheus-grafana-jaeger-and-the-elastic-stack","/learn/observing-ballerina-programs/observing-your-application-with-prometheus-grafana-jaeger-and-the-elastic-stack/","/learn/observing-ballerina-programs/","/learn/observing-ballerina-programs","/learn/observe-ballerina-programs","/learn/guides/observing-your-application-with-prometheus-grafana-jaeger-and-elastic-the-stack/","/learn/guides/observing-your-application-with-prometheus-grafana-jaeger-and-elastic-the-stack"]},"content":"\nIt consists of the three major pillars below.\n\n- **Metrics:** numeric values that are collected and aggregated over a period of time.\n- **Tracing:** the activities that occur when a request/transaction occurs in the system from the point of entry to exit.\n- **Logging:** text records of activities that occurred with relevant information along with the timestamp.\n\n## Provide observability in Ballerina\n\nMetrics, distributed tracing, and logging are key methods that reveal the internal state of the system to provide observability. Ballerina becomes fully observable by exposing itself via these three methods to various external systems allowing metrics such as request count and response time statistics to be monitored, perform distributed tracing, and analyze logs.\n\nBallerina services and any client connectors are observable by default. HTTP/HTTPS and SQL client\nconnectors use semantic tags to make tracing and metrics monitoring more informative.\n\nThis guide focuses on enabling Ballerina service observability with some of its supported systems.\n[Prometheus] and [Grafana] are used for metrics monitoring, and [Jaeger] is used for distributed tracing. \nBallerina logs can be fed to any external log monitoring system like the [Elastic Stack] to perform log monitoring and analysis.\n\n\n## Observe a Ballerina service\n\nFollow the steps below to observe a sample Ballerina service.\n\n### Step 1 - set up the prerequisites\n\nInstall [Docker](https://www.docker.com/) to set up external systems such as Jaeger,\nPrometheus, etc. For instructions, go to the [Docker documentation](https://docs.docker.com/install/) to install Docker.\n\n### Step 2 - install and configuring the external systems\n\n* Set up Prometheus for collecting metrics information by following the section on [Set up Prometheus](#set-up-prometheus)\n* Set up Grafana to visualize metrics by following the section on [Set up Grafana](#set-up-grafana)\n* Set up Jaeger to analyze tracing as mentioned in the section [Set up Jaeger](#set-up-the-jaeger-server)\n* Set up Elastic Stack only if you are interested in analyzing logs by following the section on [Set up the Elastic Stack](#set-up-the-elastic-stack)\n\n### Step 3 - create a `Hello World` Ballerina service\n \nCreate a service as shown below and save it as `hello_world_service.bal`.\n\n```ballerina\nimport ballerina/http;\nimport ballerina/log;\nimport ballerinax/prometheus as _;\nimport ballerinax/jaeger as _;\n\nservice /hello on new http:Listener(9090) {\n    \n    resource function get sayHello(http:Caller caller, http:Request req) returns error? {\n        log:printInfo(\"This is a test Info log\");\n        log:printError(\"This is a test Error log\");\n        http:Response res = new;\n        res.setPayload(\"Hello, World!\");\n        check caller->respond(res);\n    }\n    \n}\n```\n\n### Step 4 - observe the `Hello World` Ballerina service\n\nBy default, observability is not included in the executable created by Ballerina. It can be added\nby using the `--observability-included` build flag or by adding the following section to the `Ballerina.toml` file.\n\n```toml\n[build-options]\nobservabilityIncluded=true\n```\n\n>**Note:** the above configuration is included by default in the `Ballerina.toml` file generated when initiating a new \npackage using the `bal new` command.\n\nTo include the Prometheus and Jaeger extensions into the executable, the\n`ballerinax/prometheus` and `ballerinax/jaeger` modules need to be imported into your Ballerina code.\n\n```ballerina\nimport ballerinax/prometheus as _;\nimport ballerinax/jaeger as _;\n```\n\nObservability is disabled by default at runtime as well and it can be enabled selectively for metrics and tracing by adding\nthe following runtime configurations to the `Config.toml` file.\n\n```toml\n[ballerina.observe]\nmetricsEnabled=true\nmetricsReporter=\"prometheus\"\ntracingEnabled=true\ntracingProvider=\"jaeger\"\n```\n\nThe created configuration file can be passed to the Ballerina program with the `BAL_CONFIG_FILES` environment variable along with\nthe path of the configuration file. This is not necessary if the `Config.toml` file is present in the current working directory.\n\n```bash\n$ BAL_CONFIG_FILES=<path-to-conf>/Config.toml bal run --observability-included hello_world_service.bal\n\nballerina: started Prometheus HTTP listener 0.0.0.0:9797\nballerina: started publishing traces to Jaeger on localhost:55680\n```\n\nWhen Ballerina observability is enabled, the Ballerina runtime exposes internal metrics via an HTTP endpoint (/metrics) for\nmetrics monitoring and traces will be published to Jaeger. Prometheus should be configured to scrape metrics from\nthe metrics HTTP endpoint in Ballerina.\n\nBallerina logs are logged on the console. Therefore, the logs need to be redirected to a file, which can then be\npushed to [Elastic Stack](#distributed-logging) to perform the log analysis.\n\nTherefore, redirect the standard output to a file if you want to monitor logs.\n\n```bash\n$ BAL_CONFIG_FILES=<path-to-conf>/Config.toml nohup bal run --observability-included hello_world_service.bal > ballerina.log &\n```\n\n### Step 5 - send requests\n \nSend requests to <http://localhost:9090/hello/sayHello>.\n\nExample cURL command:\n\n```bash\n$ curl http://localhost:9090/hello/sayHello\n```\n\n### Step 6 - view metrics and tracing dashboards\n\nView the tracing information on Jaeger via <http://localhost:16686/> and view metrics information from the Grafana\ndashboard on <http://localhost:3000/>.\n\nA sample view of the Grafana dashboard for the `hello_world_service.bal` is shown below.\n![Grafana Sample Dashboard](/learn/images/grafana-sample-hello-world-service-stats.png \"Grafana HelloWorld Service Sample Dashboard\")\n\nA sample view of the Jaeger dashboard for the `hello_world_service.bal` is shown below. \n![Jaeger Sample Dashboard](/learn/images/jaeger-sample-dashboard.png \"Jaeger Sample Dashboard\")\n\n### Step 7 - visualize the logs\n \nIf you have configured log analytics, the logs can be viewed in Kibana via <http://localhost:5601>.\n![Kibana sample dashboard](/learn/images/kibana-sample-dashboard.png \"Kibana Sample Dashboard\")\n\n## Monitor metrics\nMetrics help to monitor the runtime behavior of a service. Therefore, metrics are a vital part of monitoring\nBallerina services. However, metrics are not the same as analytics. For example, it should not be used to perform\nper-request billing or similar use cases. Metrics are used to measure what a Ballerina service does at runtime to make\nbetter decisions using the numbers. The code generates business value when it continuously runs in production.\nTherefore, it is imperative to continuously measure the code in production.\n\nTo support Prometheus as the metrics reporter, an HTTP endpoint starts with the context\nof `/metrics` in default port 9797 when starting the Ballerina service.\n\n### Configure advanced metrics \nThis section focuses on the Ballerina configurations that are available for metrics monitoring with Prometheus,\nand the sample configuration is provided below.\n\n```toml\n[ballerina.observe]\nmetricsEnabled=true\nmetricsReporter=\"prometheus\"\n\n[ballerinax.prometheus]\nport=9797\nhost=\"0.0.0.0\"\n```\n\nThe descriptions of each configuration option are provided below with possible values.\n\nConfiguration key | Description | Default value | Possible values \n--- | --- | --- | --- \nballerina.observe. metricsEnabled | Whether metrics monitoring is enabled (true) or disabled (false) | false | true or false\nballerina.observe. metricsReporter | Reporter name that reports the collected Metrics to the remote metrics server. This is only required to be modified if a custom reporter is implemented and needs to be used. | choreo | prometheus or if any custom implementation, the name of the reporter.\nballerinax.prometheus. port | The value of the port to which the '/metrics' service will bind to. This service will be used by Prometheus to scrape the information of the Ballerina service. | 9797 | Any suitable value for port 0 - 0 - 65535. However, within that range, ports 0 - 1023 are generally reserved for specific purposes, therefore it is advisable to select a port without that range. \nballerinax.prometheus. host | The name of the host to which the '/metrics' service will bind to. This service will be used by Prometheus to scrape the information of the Ballerina service. | 0.0.0.0 | IP or Hostname or 0.0.0.0 of the node in which the Ballerina service is running.\n\n### Set up the external systems for metrics\nThere are mainly two systems involved in collecting and visualizing the metrics. [Prometheus] is used to collect the\nmetrics from the Ballerina service while [Grafana] can be used to connect to Prometheus and visualize the metrics on the dashboard.\n\n#### Set up Prometheus\n[Prometheus] is used as the monitoring system, which pulls out the metrics collected from the Ballerina `/metrics` service. This section focuses on the quick installation of Prometheus with Docker and the configuration required to \ncollect metrics from the Ballerina service with the default configurations. Follow the steps below to configure \nPrometheus. \n\n>**Tip:** There are many other ways to install Prometheus and you can find possible options from the\n[installation guide](https://prometheus.io/docs/prometheus/latest/installation/).\n\n1. Create a `prometheus.yml` file in the `/tmp/` directory.\n\n2. Add the following content to the `/tmp/prometheus.yml` file.\n\n    ```yaml\n    global:\n      scrape_interval:     15s\n      evaluation_interval: 15s\n    \n    scrape_configs:\n      - job_name: 'prometheus'\n        static_configs:\n          - targets: ['a.b.c.d:9797']\n    ```\n\n    Here, the `'a.b.c.d:9797'` targets should contain the host and port of the `/metrics` service that is exposed from \n    Ballerina for metrics collection. Add the IP of the host in which the Ballerina service is running as `a.b.c.d` and its\n    port (default `9797`).\n    If you need more information, go to the [Prometheus documentation](https://prometheus.io/docs/introduction/first_steps/).\n    \n    If your Ballerina service is running on localhost and Prometheus in a Docker container,\n    add the target as `host.docker.internal:9797` to access the localhost from Docker.\n\n3.  Start the Prometheus server in a Docker container with the command below.\n\n    ```bash\n    $ docker run -p 19090:9090 -v /tmp/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus\n    ```\n    \n4.  Go to <http://localhost:19090/> and check whether you can see the Prometheus graph.\nBallerina metrics should appear in Prometheus graph's metrics list when the Ballerina service is started.\n\n#### Set up Grafana\nLet’s use [Grafana] to visualize metrics in a dashboard. For this, we need to install Grafana and configure\nPrometheus as a data source. Follow the steps below to configure Grafana.\n\n1. Start Grafana as a Docker container with the command below.\n\n    ```bash\n    $ docker run -d --name=grafana -p 3000:3000 grafana/grafana\n    ```\n    For more information, go to [Grafana in Docker Hub](https://hub.docker.com/r/grafana/grafana/).\n\n2. Go to <http://localhost:3000/> to access the Grafana dashboard running on Docker.\n\n3. Login to the dashboard with the default user, username: `admin` and password: `admin`\n\n4. Add Prometheus as a data source with `Browser` access configuration as provided below.\n\n    ![Grafana Prometheus datasource](/learn/images/grafana-prometheus-datasource.png \"Grafana Prometheus Datasource\")\n\n5. Import the Grafana dashboard designed to visualize Ballerina metrics from [https://grafana.com/dashboards/5841](https://grafana.com/dashboards/5841).\nThis dashboard consists of service and client invocation level metrics in near real-time view. \n\n    The Ballerina HTTP Service Metrics Dashboard Panel will be as shown below.\n    ![Ballerina Service Metrics](/learn/images/grafana-ballerina-metrics-1.png \"Ballerina Sample Service Metrics Dashboard\")\n\n\n## Distributed tracing\n\nTracing provides information regarding the roundtrip of a service invocation based on the concept of spans, which are\nstructured in a hierarchy based on the cause and effect concept. A trace can spread across several services that can be\ndeployed in several nodes, depicting a high-level view of interconnections among services as well, hence coining the\nterm distributed tracing.\n\nA span is a logical unit of work, which encapsulates a start and end time as well as metadata to give more meaning to\nthe unit of work being completed. For example, a span representing a client call to an HTTP endpoint would give the\nuser the latency of the client call and metadata like the HTTP URL being called, and the HTTP method used. If the span\nrepresents an SQL client call, the metadata would include the query being executed.\n\nTracing gives the user a high-level view of how a single service invocation is processed across several distributed\nmicroservices.\n\n* Identify service bottlenecks - The user can monitor the latencies and identify when a service invocation slows down,\npinpoint where the slowing down happens (by looking at the span latencies), and take action to improve the latency.\n* Error identification - If an error occurs during the service invocation, it will show up in the list of traces.\nThe user can easily identify where the error occurred and information of the error will be attached to the relevant\nspan as metadata.\n\nBallerina supports [OpenTelemetry](https://opentelemetry.io/) standards by default. This means that Ballerina services\ncan be traced using OpenTelemetry implementations like [Jaeger](http://www.jaegertracing.io/).\n\n### Configure advanced tracing \n\nTracing can be enabled in Ballerina with the few configurations mentioned above in the\n[Observe a Ballerina service](#observe-a-ballerina-service) section.\nThis section mainly focuses on the configuration options with the description and possible values.\n\nA sample configuration that enables tracing and uses Jaeger as the tracer is provided below.\n\n```toml\n[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"jaeger\"\n```\n\nThe table below provides the descriptions of each configuration option and possible values that can be assigned.\n\nConfiguration key | Description | Default value | Possible values\n--- | --- | --- | --- \nballerina.observe.tracingEnabled | Whether tracing is enabled (true) or disabled (false) | false | true or false\nballerina.observe.tracingProvider | The tracer name, which implements the tracer interface. | choreo | jaeger or the name of the tracer of any custom implementation.\n\n#### Use the Jaeger extension\nBelow are the sample configuration options that are available to support Jaeger as the tracer provider in Ballerina.\n\n```toml\n[ballerina.observe]\ntracingEnabled=true\ntracingProvider=\"jaeger\"\n\n[ballerinax.jaeger]\nagentHostname=\"localhost\"\nagentPort=55680\nsamplerType=\"const\"\nsamplerParam=1.0\nreporterFlushInterval=2000\nreporterBufferSize=1000\n```\n\nThe table below provides the descriptions of each configuration option and possible values that can be assigned.\n\nConfiguration key | Description | Default value | Possible values \n--- | --- | --- | --- \nballerina.observe. agentHostname | Hostname of the Jaeger agent | localhost | IP or hostname of the Jaeger agent. If it is running on the same node as Ballerina, it can be localhost. \nballerina.observe. agentPort | Port of the Jaeger agent | 55680 | The port on which the Jaeger agent is listening.\nballerina.observe. samplerType | Type of the sampling methods used in the Jaeger tracer. | const | `const`, `probabilistic`, or `ratelimiting`.\nballerina.observe. samplerParam | It is a floating value. Based on the sampler type, the effect of the sampler param varies | 1.0 | For `const` `0` (no sampling) or `1` (sample all spans), for `probabilistic` `0.0` to `1.0`, for `ratelimiting` any positive integer (rate per second).\nballerina.observe. reporterFlushInterval | The Jaeger client will be sending the spans to the agent at this interval. | 2000 | Any positive integer value.\nballerina.observe. reporterBufferSize | Queue size of the Jaeger client. | 2000 | Any positive integer value.\n\n### Set up the external systems for tracing\nYou can configure Ballerina to support distributed tracing with Jaeger. This section focuses on configuring\nJaeger with Docker as a quick installation.\n\n#### Set up the Jaeger server\n\nThere are many possible ways to deploy Jaeger. For more information, see [Jaeger Deployment](https://www.jaegertracing.io/docs/deployment/). This focuses on an all-in-one deployment with Docker.\n\n1. Install Jaeger via Docker and start the Docker container by executing the command below.\n\n    ```bash\n    $ docker run -d -p 13133:13133 -p 16686:16686 -p 55680:55680 jaegertracing/opentelemetry-all-in-one\n    ```\n\n2. Go to <http://localhost:16686> and load the web UI of Jaeger to make sure it is functioning properly.\n\n    The image below is the sample tracing information you can see in Jaeger.\n    \n    ![Jaeger Tracing Dashboard](/learn/images/jaeger-tracing-dashboard.png \"Jaeger Tracing Dashboard\")\n\n## Distributed logging\nIn Ballerina, distributed logging and analysis are supported by the Elastic Stack. Ballerina has a log module for logging into the console. To monitor the logs, the Ballerina standard output needs to be redirected to a file.\n\nThis can be done by running the Ballerina service as below.\n\n```bash\n$ nohup bal run hello_world_service.bal > ballerina.log &\n```\n\nYou can view the logs with the command below.\n\n```bash\n$ tail -f ~/wso2-ballerina/workspace/ballerina.log\n```\n\n### Set up the external systems for log analytics\n\n#### Set up Elastic Stack\nThe Elastic Stack comprises the following components.\n\n1. Beats - Multiple agents that ship data to Logstash or Elasticsearch. In our context, Filebeat will ship the Ballerina logs to Logstash. Filebeat should be a container running on the same host as the Ballerina service. This is so that the log file (ballerina.log) can be mounted to the Filebeat container.\n2. Logstash - Used to process and structure the log files received from Filebeat and send them to Elasticsearch.\n3. Elasticsearch - Storage and indexing of the logs sent by Logstash.\n4. Kibana - Visualizes the data stored in Elasticsearch.\n\nElasticsearch and Kibana are provided as [Cloud Services](https://www.elastic.co/cloud).\nAlternatively, Docker containers can be used to set up Elasticsearch and Kibana as well.\n\n1. Download the Docker images using the following commands.\n\n    ```bash\n    # Elasticsearch Image\n    $ docker pull docker.elastic.co/elasticsearch/elasticsearch:6.5.1\n    # Kibana Image\n    $ docker pull docker.elastic.co/kibana/kibana:6.5.1\n    # Filebeat Image\n    $ docker pull docker.elastic.co/beats/filebeat:6.5.1\n    # Logstash Image\n    $ docker pull docker.elastic.co/logstash/logstash:6.5.1\n    ```\n\n2. Start Elasticsearch and Kibana containers by executing the following commands.\n\n    ```bash\n    $ docker run -p 9200:9200 -p 9300:9300 -it -h elasticsearch --name elasticsearch docker.elastic.co/elasticsearch/elasticsearch:6.5.1\n    $ docker run -p 5601:5601 -h kibana --name kibana --link elasticsearch:elasticsearch docker.elastic.co/kibana/kibana:6.5.1\n    ```\n    \n    If you are using Linux, you may have to increase the `vm.max_map_count` for the Elasticsearch container to start. \n    Execute the following command to do that.\n    \n    ```bash\n    $ sudo sysctl -w vm.max_map_count=262144\n    ```\n\n3. Create a `logstash.conf` file in the `/tmp/pipeline/` directory and include the following content in the file.\n\n    ```\n    input {\n      beats {\n        port => 5044\n        }\n    }\n    filter {\n      grok  {\n        match => { \"message\" => \"%{TIMESTAMP_ISO8601:date}%{SPACE}%{WORD:logLevel}%{SPACE}\\[%{GREEDYDATA:module}\\]%{SPACE}\\-%{SPACE}%{GREEDYDATA:logMessage}\"}\n      }\n    }\n    output {\n        elasticsearch {\n            hosts => \"elasticsearch:9200\"\n            index => \"ballerina\"\n          document_type => \"ballerina_logs\"\n        }\n    }\n    ```\n    \n    Here, the 3 stages are specified in the pipeline. Input is specified as beats and listens to port 5044. \n    A Grok filter is used to structure the Ballerina logs and the output is specified to push to Elasticsearch on\n    `elasticsearch:9200`.\n\n4. Start the Logstash container by executing the following command.\n\n    ```bash\n    $ docker run -h logstash --name logstash --link elasticsearch:elasticsearch -it --rm -v /tmp/pipeline:/usr/share/logstash/pipeline/ -p 5044:5044 docker.elastic.co/logstash/logstash:6.5.1\n    ```\n\n5. Configure Filebeat to ship the Ballerina logs. Create a `filebeat.yml` file in the `/tmp/` directory and include the following content in the file.\n\n    ```\n    filebeat.prospectors:\n    - type: log\n      paths:\n        - /usr/share/filebeat/ballerina.log\n    output.logstash:\n      hosts: [\"logstash:5044\"]\n    ```\n    \n6. Start the Filebeat container with the following command.\n\n    ```bash\n    $ docker run -v /tmp/filebeat.yml:/usr/share/filebeat/filebeat.yml -v /<path-to-ballerina.log>/ballerina.log:/usr/share/filebeat/ballerina.log --link logstash:logstash docker.elastic.co/beats/filebeat:6.5.1\n    ```\n    \n    The `-v` flag is used for bind mounting, where the container will read the file from the host machine. Provide the path to the `ballerina.log` file to be bind-mounted to the filebeat container.\n\n7. Access Kibana to visualize the logs at <http://localhost:5601>. Add an index named `ballerina` and click on `Discover` to visualize the logs.\n\n[Prometheus]: https://prometheus.io/\n[Grafana]: https://grafana.com/\n[Jaeger]: https://www.jaegertracing.io/\n[Elastic Stack]: https://www.elastic.co/","id":"observe-ballerina-programs","sub":"configure-observe","third":"","slug":"configure-observe/observe-ballerina-programs"},"__N_SSG":true}